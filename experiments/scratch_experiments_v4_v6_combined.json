{
  "name": "Scratch Model Combined v4-v6",
  "description": "Run all expanded experiment variants from v4, v5, and v6 in one go.",
  "created_at": "2025-12-06",
  "experiments": [
    {
      "name": "V4-01: Char + Deeper Enc + Longer Train",
      "description": "Char vocab, pyramidal encoder larger/longer.",
      "config": {
        "token_type": "char",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "encoder_hidden_size": 256,
        "decoder_dim": 512,
        "attention_dim": 256,
        "learning_rate": 5e-4,
        "num_epochs": 150
      }
    },
    {
      "name": "V4-02: Word + GRU Decoder",
      "description": "Word vocab with GRU decoder.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "gru",
        "learning_rate": 7e-4,
        "num_epochs": 120
      }
    },
    {
      "name": "V4-03: Word + CTC Joint",
      "description": "Word vocab with joint CTC-attention.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "learning_rate": 5e-4,
        "num_epochs": 120,
        "use_ctc": true,
        "ctc_weight": 0.3
      }
    },
    {
      "name": "V4-04: Char + Low Dropout",
      "description": "Char vocab with reduced dropout.",
      "config": {
        "token_type": "char",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "learning_rate": 5e-4,
        "num_epochs": 100,
        "dropout": 0.1
      }
    },
    {
      "name": "V4-05: Word + Higher LR",
      "description": "Word vocab with higher learning rate.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "learning_rate": 1e-3,
        "num_epochs": 100
      }
    },
    {
      "name": "V4-06: Word + Larger Model",
      "description": "Word vocab with larger hidden sizes.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "encoder_hidden_size": 256,
        "decoder_dim": 512,
        "attention_dim": 256,
        "learning_rate": 5e-4,
        "num_epochs": 120
      }
    },

    {
      "name": "V5-01: Char + Standard Encoder",
      "description": "Character vocab with non-pyramidal encoder.",
      "config": {
        "token_type": "char",
        "encoder_type": "standard",
        "decoder_type": "lstm",
        "learning_rate": 5e-4,
        "num_epochs": 120
      }
    },
    {
      "name": "V5-02: Char + CTC Joint",
      "description": "Character vocab with joint CTC-attention.",
      "config": {
        "token_type": "char",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "learning_rate": 5e-4,
        "num_epochs": 120,
        "use_ctc": true,
        "ctc_weight": 0.3
      }
    },
    {
      "name": "V5-03: Word + Larger Hidden",
      "description": "Word vocab with bigger encoder/decoder.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "encoder_hidden_size": 256,
        "decoder_dim": 512,
        "attention_dim": 256,
        "learning_rate": 6e-4,
        "num_epochs": 120
      }
    },
    {
      "name": "V5-04: Char + Longer, Lower LR",
      "description": "Char vocab with lower LR but longer training.",
      "config": {
        "token_type": "char",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "learning_rate": 3e-4,
        "num_epochs": 180
      }
    },
    {
      "name": "V5-05: Word + Dropout 0.2",
      "description": "Word vocab with dropout 0.2.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "lstm",
        "learning_rate": 5e-4,
        "num_epochs": 100,
        "dropout": 0.2
      }
    },

    {
      "name": "V6-01: Word+GRU Larger + CTC 0.3",
      "description": "Word+GRU larger dims with CTC weight 0.3.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "gru",
        "encoder_hidden_size": 256,
        "decoder_dim": 512,
        "attention_dim": 256,
        "learning_rate": 5e-4,
        "num_epochs": 120,
        "use_ctc": true,
        "ctc_weight": 0.3
      }
    },
    {
      "name": "V6-02: Word+GRU Larger + CTC 0.2",
      "description": "Same as V6-01 with CTC weight 0.2.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "gru",
        "encoder_hidden_size": 256,
        "decoder_dim": 512,
        "attention_dim": 256,
        "learning_rate": 5e-4,
        "num_epochs": 120,
        "use_ctc": true,
        "ctc_weight": 0.2
      }
    },
    {
      "name": "V6-03: Word+GRU Larger + CTC 0.4",
      "description": "Same as V6-01 with CTC weight 0.4.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "gru",
        "encoder_hidden_size": 256,
        "decoder_dim": 512,
        "attention_dim": 256,
        "learning_rate": 5e-4,
        "num_epochs": 120,
        "use_ctc": true,
        "ctc_weight": 0.4
      }
    },
    {
      "name": "V6-04: Word+GRU Deeper + CTC",
      "description": "4-layer pyramidal encoder, GRU decoder, CTC 0.3.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "gru",
        "encoder_num_layers": 4,
        "learning_rate": 5e-4,
        "num_epochs": 120,
        "use_ctc": true,
        "ctc_weight": 0.3
      }
    },
    {
      "name": "V6-05: Word+GRU Larger + Low Dropout + CTC",
      "description": "Larger GRU model, dropout 0.1, CTC 0.3.",
      "config": {
        "token_type": "word",
        "encoder_type": "pyramidal",
        "decoder_type": "gru",
        "encoder_hidden_size": 256,
        "decoder_dim": 512,
        "attention_dim": 256,
        "dropout": 0.1,
        "learning_rate": 5e-4,
        "num_epochs": 120,
        "use_ctc": true,
        "ctc_weight": 0.3
      }
    }
  ]
}
