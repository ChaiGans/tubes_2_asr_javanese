{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Javanese ASR Training on Google Colab\n",
                "\n",
                "This notebook trains a Listen, Attend and Spell (LAS) style seq2seq ASR model for Javanese on Google Colab GPU.\n",
                "\n",
                "## Setup Instructions:\n",
                "1. Upload this notebook to Google Colab\n",
                "2. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU (T4)\n",
                "3. Upload your data:\n",
                "   - `audio_input/` folder (all WAV files)\n",
                "   - `transcripts.csv` file\n",
                "4. Run all cells\n",
                "\n",
                "## Expected Training Time:\n",
                "- 100 epochs: ~3-5 hours on T4 GPU\n",
                "- 200 epochs: ~6-10 hours on T4 GPU"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Check GPU Availability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch version: 2.9.0+cu126\n",
                        "CUDA available: False\n",
                        "‚ö†Ô∏è WARNING: No GPU detected! Training will be very slow.\n",
                        "Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be very slow.\")\n",
                "    print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q editdistance soundfile tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Upload Your Data\n",
                "\n",
                "**Option A: Upload from local computer**\n",
                "- Click the folder icon on the left sidebar\n",
                "- Create folder: `audio_input`\n",
                "- Upload all WAV files to `audio_input/`\n",
                "- Upload `transcripts.csv` to root\n",
                "\n",
                "**Option B: Mount Google Drive (if data is in Drive)**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Option B: Uncomment to mount Google Drive\n",
                "# from google.colab import drive\n",
                "# drive.mount('/content/drive')\n",
                "\n",
                "# Then copy your data from Drive:\n",
                "# !cp -r /content/drive/MyDrive/javanese_asr/audio_input ./\n",
                "# !cp /content/drive/MyDrive/javanese_asr/transcripts.csv ./"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Upload Code Files\n",
                "\n",
                "Upload these Python files to Colab:\n",
                "- `model.py`\n",
                "- `features.py`\n",
                "- `vocab.py`\n",
                "- `dataset.py`\n",
                "- `metrics.py`\n",
                "- `decoder.py`\n",
                "- `utils.py`\n",
                "- `config.py`\n",
                "- `train.py`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚ùå Missing files:\n",
                        "  - model.py\n",
                        "  - features.py\n",
                        "  - vocab.py\n",
                        "  - dataset.py\n",
                        "  - metrics.py\n",
                        "  - decoder.py\n",
                        "  - utils.py\n",
                        "  - config.py\n",
                        "  - train.py\n",
                        "\n",
                        "Please upload these files to continue.\n",
                        "‚ùå Data not found. Please upload audio_input/ and transcripts.csv\n"
                    ]
                }
            ],
            "source": [
                "# Verify files are uploaded\n",
                "import os\n",
                "required_files = ['model.py', 'features.py', 'vocab.py', 'dataset.py', \n",
                "                  'metrics.py', 'decoder.py', 'utils.py', 'config.py', 'train.py']\n",
                "\n",
                "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
                "if missing_files:\n",
                "    print(\"‚ùå Missing files:\")\n",
                "    for f in missing_files:\n",
                "        print(f\"  - {f}\")\n",
                "    print(\"\\nPlease upload these files to continue.\")\n",
                "else:\n",
                "    print(\"‚úÖ All code files found!\")\n",
                "\n",
                "# Check data\n",
                "if os.path.exists('audio_input') and os.path.exists('transcripts.csv'):\n",
                "    num_audio = len([f for f in os.listdir('audio_input') if f.endswith('.wav')])\n",
                "    print(f\"‚úÖ Data found: {num_audio} audio files\")\n",
                "else:\n",
                "    print(\"‚ùå Data not found. Please upload audio_input/ and transcripts.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Configure Training Settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Config updated for Colab (GPU enabled, batch_size=16, epochs=100)\n"
                    ]
                }
            ],
            "source": [
                "# Modify config.py for Colab\n",
                "config_content = '''\n",
                "from dataclasses import dataclass\n",
                "\n",
                "@dataclass\n",
                "class Config:\n",
                "    # Data paths\n",
                "    audio_dir: str = \"audio_input\"\n",
                "    transcript_file: str = \"transcripts.csv\"\n",
                "    vocab_path: str = \"vocab.json\"\n",
                "    \n",
                "    # Training\n",
                "    batch_size: int = 16  # Increased for GPU\n",
                "    num_epochs: int = 100  # Full training\n",
                "    learning_rate: float = 1e-3\n",
                "    grad_clip_norm: float = 5.0\n",
                "    teacher_forcing_ratio: float = 1.0\n",
                "    \n",
                "    # Model architecture\n",
                "    input_dim: int = 80\n",
                "    encoder_hidden_size: int = 128\n",
                "    encoder_num_layers: int = 3\n",
                "    decoder_dim: int = 256\n",
                "    attention_dim: int = 128\n",
                "    embedding_dim: int = 64\n",
                "    dropout: float = 0.3\n",
                "    \n",
                "    # CTC settings\n",
                "    use_ctc: bool = False\n",
                "    ctc_weight: float = 0.3\n",
                "    \n",
                "    # Feature extraction\n",
                "    sample_rate: int = 16000\n",
                "    n_mels: int = 80\n",
                "    win_length_ms: float = 25.0\n",
                "    hop_length_ms: float = 10.0\n",
                "    \n",
                "    # Augmentation\n",
                "    apply_cmvn: bool = True\n",
                "    apply_spec_augment: bool = True\n",
                "    speed_perturb: bool = False\n",
                "    \n",
                "    # Validation\n",
                "    val_split: float = 0.1\n",
                "    val_every_n_steps: int = 500\n",
                "    \n",
                "    # Checkpointing\n",
                "    checkpoint_dir: str = \"checkpoints\"\n",
                "    save_every_n_epochs: int = 10\n",
                "    \n",
                "    # Decoding\n",
                "    max_decode_len: int = 200\n",
                "    beam_size: int = 5\n",
                "    \n",
                "    # Device\n",
                "    device: str = \"cuda\"  # Use GPU on Colab\n",
                "    \n",
                "    # Random seed\n",
                "    seed: int = 42\n",
                "'''\n",
                "\n",
                "with open('config.py', 'w') as f:\n",
                "    f.write(config_content)\n",
                "\n",
                "print(\"‚úÖ Config updated for Colab (GPU enabled, batch_size=16, epochs=100)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Build Vocabulary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'vocab'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipython-input-4013950866.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building vocabulary from transcripts...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transcripts.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vocab.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n‚úÖ Vocabulary built with {len(vocab)} tokens\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vocab'",
                        "",
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "from vocab import build_vocab_from_file\n",
                "\n",
                "print(\"Building vocabulary from transcripts...\")\n",
                "vocab = build_vocab_from_file(\"transcripts.csv\", save_path=\"vocab.json\")\n",
                "print(f\"\\n‚úÖ Vocabulary built with {len(vocab)} tokens\")\n",
                "print(f\"Special tokens: {vocab.special_tokens}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Start Training\n",
                "\n",
                "This will take several hours. You can monitor progress in real-time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run training\n",
                "!python train.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Monitor Training Progress\n",
                "\n",
                "While training is running, you can check:\n",
                "- Training loss (should decrease from ~4.0 to <1.0)\n",
                "- Validation CER (should decrease from ~90% to <20%)\n",
                "- Best model saved at `checkpoints/best_model.pt`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Download Trained Model\n",
                "\n",
                "After training completes, download your model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "# Download best model\n",
                "if os.path.exists('checkpoints/best_model.pt'):\n",
                "    files.download('checkpoints/best_model.pt')\n",
                "    print(\"‚úÖ Downloaded best_model.pt\")\n",
                "\n",
                "# Download vocabulary\n",
                "if os.path.exists('vocab.json'):\n",
                "    files.download('vocab.json')\n",
                "    print(\"‚úÖ Downloaded vocab.json\")\n",
                "\n",
                "# Download all checkpoints (optional)\n",
                "# !zip -r checkpoints.zip checkpoints/\n",
                "# files.download('checkpoints.zip')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Test Inference\n",
                "\n",
                "Test the trained model on a sample audio file:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from model import Seq2SeqASR\n",
                "from vocab import Vocabulary\n",
                "from features import LogMelFeatureExtractor, load_audio, CMVN\n",
                "from decoder import GreedyDecoder\n",
                "from utils import load_checkpoint\n",
                "from config import Config\n",
                "\n",
                "# Load config and vocab\n",
                "cfg = Config()\n",
                "vocab = Vocabulary.load('vocab.json')\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "# Create model\n",
                "model = Seq2SeqASR(\n",
                "    vocab_size=len(vocab),\n",
                "    input_dim=cfg.input_dim,\n",
                "    encoder_hidden_size=cfg.encoder_hidden_size,\n",
                "    encoder_num_layers=cfg.encoder_num_layers,\n",
                "    decoder_dim=cfg.decoder_dim,\n",
                "    attention_dim=cfg.attention_dim,\n",
                "    embedding_dim=cfg.embedding_dim,\n",
                "    dropout=cfg.dropout,\n",
                "    use_ctc=cfg.use_ctc,\n",
                "    ctc_weight=cfg.ctc_weight\n",
                ").to(device)\n",
                "\n",
                "# Load checkpoint\n",
                "load_checkpoint('checkpoints/best_model.pt', model, device=device)\n",
                "model.eval()\n",
                "\n",
                "# Create decoder\n",
                "decoder = GreedyDecoder(model, vocab, max_len=200, device=device)\n",
                "\n",
                "# Test on a sample file\n",
                "test_file = 'audio_input/speaker03_m_nn_utt01.wav'  # Change to your file\n",
                "if os.path.exists(test_file):\n",
                "    # Load and process audio\n",
                "    feature_extractor = LogMelFeatureExtractor()\n",
                "    waveform, sr = load_audio(test_file, target_sr=16000)\n",
                "    features = feature_extractor(waveform)\n",
                "    cmvn = CMVN()\n",
                "    features = cmvn(features)\n",
                "    \n",
                "    # Add batch dimension\n",
                "    features = features.unsqueeze(0).to(device)\n",
                "    feature_lengths = torch.tensor([features.size(1)], dtype=torch.long).to(device)\n",
                "    \n",
                "    # Decode\n",
                "    transcript = decoder.decode(features, feature_lengths)[0]\n",
                "    \n",
                "    print(f\"\\nüé§ Audio: {test_file}\")\n",
                "    print(f\"üìù Transcript: {transcript}\")\n",
                "else:\n",
                "    print(f\"File not found: {test_file}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Save to Google Drive (Optional)\n",
                "\n",
                "Save your trained model to Google Drive for permanent storage:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Create directory in Drive\n",
                "!mkdir -p /content/drive/MyDrive/javanese_asr_trained\n",
                "\n",
                "# Copy checkpoints and vocab\n",
                "!cp -r checkpoints /content/drive/MyDrive/javanese_asr_trained/\n",
                "!cp vocab.json /content/drive/MyDrive/javanese_asr_trained/\n",
                "\n",
                "print(\"‚úÖ Saved to Google Drive: /MyDrive/javanese_asr_trained/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tips for Better Results:\n",
                "\n",
                "1. **Training Duration**: Train for at least 100 epochs (3-5 hours on T4 GPU)\n",
                "2. **Monitor CER**: Good models achieve <20% CER on validation set\n",
                "3. **Batch Size**: Increase to 32 if you have enough GPU memory\n",
                "4. **Enable CTC**: Set `use_ctc=True` in config for better alignment\n",
                "5. **Data Quality**: Remove corrupted audio files before training\n",
                "\n",
                "## Troubleshooting:\n",
                "\n",
                "- **Out of Memory**: Reduce `batch_size` to 8 or 4\n",
                "- **Slow Training**: Make sure GPU is enabled (check cell 1)\n",
                "- **High CER**: Train longer (200+ epochs) or enable CTC\n",
                "- **Disconnection**: Colab disconnects after ~12 hours. Save to Drive regularly!"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
